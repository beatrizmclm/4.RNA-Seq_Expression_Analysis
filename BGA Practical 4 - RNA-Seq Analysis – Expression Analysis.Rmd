---
title: "RNA-Seq data Analysis - Expression Analysis"
author: "Beatriz Manso"
date: '2022-04-07'
output: 
  distill::distill_article:
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: true
    code_folding: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.path = "C:/Users/manso/Desktop/practical/BGA-Practical-4---RNA-Seq-Analysis---Expression-Analysis_files/figure-html5" 
)
```

# Introduction

By quantifying the activity of RNA in a biological sample, gene expression can provide valuable insights into disease nature and its treatment. The RNA-Seq assay is one of the fastest growing Next Generation Sequencing (NGS) approaches used to assess gene expression and alternative splicing, where both known and novel features can be detected in a single assay, allowing for the identification of transcript isoforms, gene fusions, and single nucleotide variations as well as other features without a prior knowledge of the sequence.

# Methods

## 1. Set Working Directory, Install necessary packages and load libraries:

```{r eval=FALSE}
setwd("C:/Users/manso/Desktop/practical")
```

```{r}
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("Rsubread")
BiocManager::install("edgeR")
BiocManager::install("affy")
BiocManager::install("pheatmap")
BiocManager::install("corrplot")

library(edgeR)
library(Rsubread)
library(Rsamtools) 
library(affy)
library(GEOquery)
library(tidyverse)
library(pheatmap)
library(stats)
library(corrplot)
library(knitr)

```

## 2. Alignment

### 2.1.List the fastq files:

```{r}
fastq.files <- list.files(path = "C:/Users/manso/Desktop/practical", pattern = ".fastq$", full.names = TRUE)

fastq.files
```

### 2.2. Build the index:

Lets use the Saccharomyces reference genome for now because the human genome takes a long time to complete.

```{r}
buildindex(basename="ht",reference="GCF_000146045.2_R64_genomic.fna")
```

### 2.3. Aligning reads with reference genome

```{r}
reads1 <- list.files( path = "C:/Users/manso/Desktop/practical", pattern = "*_1.fastq$" )

reads2 <- list.files( path = "C:/Users/manso/Desktop/practical", pattern = "*_2.fastq$" )

align(index="ht",readfile1=reads1,readfile2=reads2,input_format="FASTQ",output_format="BAM",nthreads=16)
```

## 3. Post alignment quality control

### 3.1. Setup a BamFile object:

```{r}
bamFile <- BamFile(file = "SRR14094802_1.sorted.bam", index= "SRR14094802_1.sorted.bam.bai")

bamFile
```

In Ubunto terminal - To create a BAM index:\
- You must first sort the BAM file to create a sorted.bam - Run samtools index with the sorted.bam as input - This will create a file named sorted.bam.bai which\
contains the index

```{bash eval=FALSE}
samtools sort  SRR14094802_1.fastq.subread.BAM -o  SRR14094802_1.sorted.bam

samtools index SRR14094802_1.sorted.bam SRR14094802_1.sorted.bam.bai
```

### 3.2. High-level information can be accessed with seqinfo()

```{r eval=FALSE, include=TRUE}
seqinfo(bamFile)
```

### 3.3. Read aligned reads using scanBam()

```{r}
aln <- scanBam(bamFile)
length(aln)
class(aln)
```

In the case of scanBam() it's possible to get output from multiple genomic regions,here we get back a list of length 1. If it returns a list \>1, we subset that list to a single list and then display that information.

```{r}
aln <- aln[[1]]
names(aln)
```

```{r}
lapply(aln, function(xx) xx[1])

```

### 3.4. Get BAM flag sumary

```{r}
quickBamFlagSummary(bamFile)
```

## 4. Counting and normalisation methods

For this step we'll use The Human sample SRR8472776.bam

### 4.1. Counting - Quantification with featureCounts

```{r}
SRRcount <- featureCounts(files="SRR8472776.bam",
                       annot.ext="gencode.v29.annotation.gtf",
                       isGTFAnnotationFile=TRUE, GTF.featureType="exon", 
                       GTF.attrType="gene_id")

```

View the count file:

```{r}
View(SRRcount[["counts"]])
```

-   Extract the count file as csv file

```{r}
SRR8472776 <- SRRcount[["counts"]]
write.csv(SRR8472776, "SRR8472776_counts.csv")

```

-   Read the count file

```{r}
#Read files SRP029880.raw_counts.tsv as count file
Count_file <- read.table(file="SRP029880.raw_counts.tsv",
                        sep = '\t', header = TRUE, 
                        fill = TRUE)

counts <- as.matrix(Count_file)

summary(counts)

```

### 4.2. Normalisation for RNA sequencing data

-   **Method 1: Computing CPM With formula**

```{r}
#To compute the CPM values for each sample (excluding the width column):
cpm <- apply(subset(counts, select = c(-width)), 
             2, function(x) x/sum(as.numeric(x)) * 10^6)

head(cpm)
```

-   Check that the sum of each column after normalisation equals to 10\^6 (except the width column):

```{r}
colSums(cpm)
```

- **Method 2: Computing CPM with edgeR**

Use the "ExpData.csv" file for this method We have to change the Gene_id column as the row names

Read the ExpData.csv count file:

```{r}
Counts_NP1PE1 <- read.csv(file="ExpData.csv" , header =TRUE)
```

Change the Gene_id column as row names:

```{r}
rownames(Counts_NP1PE1) <- Counts_NP1PE1[,1]

Counts_NP1PE1[,1] <- NULL
```

**Computing CPM**

```{r}
# Creates a DGEList object from a table of counts (rows=features, columns=samples), group indicator for each column

group <-(c(rep("NP", 8), rep("PE", 8)))

y <- DGEList(counts=Counts_NP1PE1, group=group)


dge <- calcNormFactors(y) # Calculate norm. factors

normcounts <- cpm(dge, log =FALSE) # Get cpm normalized counts

```

**Computing RPKM**

```{r}
# create a vector of gene lengths
geneLengths <- as.vector(subset(counts, select = c(width)))  

# compute rpkm
rpkm <- apply(X = subset(counts, select = c(-width)),
              MARGIN = 2, 
FUN = function(x) 10^9 * x / geneLengths /
 sum(as.numeric(x))) 

head(rpkm)

```

Check the sample sizes of RPKM. Notice that the sums of samples are all different:

```{r}
colSums(rpkm)
```

Find gene length normalized values:

```{r}
rpk <- apply( subset(counts, select = c(-width)), 2, 
function(x) x/(geneLengths/1000))

#normalize by the sample size using rpk values
head(rpk)
```

**Computing TPM**

```{r}
tpm <- apply(rpk, 2, function(x) x / sum(as.numeric(x)) * 10^6)
head(tpm)
```

Check the sample sizes of tpm. Notice that the sums of samples are all equal to 10\^6:

```{r}
colSums(tpm)
```

### 4.3. Normalisation for Microarray data (Robust Multiarray Averaging (RMA))

Script to perform RMA normalization:

```{r}
# get supplementary files
getGEOSuppFiles("GSE148537")

# untar files
untar("GSE148537/GSE148537_RAW.tar", exdir="data/")

```

```{r}
# reading in .cel files
raw.data <- ReadAffy(celfile.path = "data/")

```

```{r}
# performing RMA normalization
normalized.data <- rma(raw.data)
```

```{r}
# get expression estimates
normalized.expr <- as.data.frame(exprs(normalized.data))
```

```{r}
# map probe IDs to gene symbols
gse <- getGEO("GSE148537", GSEMatrix = TRUE)
```

```{r}
# fetch feature data to get ID - gene symbol mapping
feature.data <- gse$GSE148537_series_matrix.txt.gz@featureData@data
```

```{r}
# subset
feature.data <- feature.data[,c(1,11)]

normalized.expr <- normalized.expr %>%
 rownames_to_column(var = 'ID') %>%
 inner_join(., feature.data, by = 'ID')
```

## 5. Exploratory analysis of the read count table

**- Clustering**

Compute the variance of each gene across samples:

```{r}
V <- apply(tpm, 1, var)
```

Sort the results by variance in decreasing order and select the top 100 genes:

```{r}
selectedGenes <- names(V[order(V, decreasing = T)][1:100])
```

Now we can produce a heatmap where samples and genes are clustered:

```{r}
pheatmap(tpm[selectedGenes,], scale = 'row', show_rownames = FALSE)

```

**Correlation plots**

```{r}
correlationMatrix <- cor(tpm)
```

Have a look at how the correlation matrix looks:

```{r}
kable(correlationMatrix,booktabs = TRUE)
```

We can also draw more colourful correlation plots using the corrplot package:

```{r}
# The correlation plot order by the results of the hierarchical clustering 
corrplot(correlationMatrix, order = 'hclust')
```

Pairwise correlation scores on the plot:

```{r}
corrplot(correlationMatrix, order = 'hclust', addrect = 2, addCoef.col = 'white')
```

Plot the correlation matrix as a heatmap:

```{r}
pheatmap(correlationMatrix)
```
